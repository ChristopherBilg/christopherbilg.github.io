<!DOCTYPE html>
<html lang="en" color-mode="user">
  <head>
    <meta charset="UTF-8" />
    <meta name="description" content="Christopher Bilger's Portfolio" />
    <meta name="keywords" content="Resume, Portfolio, Personal, Projects" />
    <meta name="author" content="Christopher Bilger" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <meta property="og:url" content="https://chrisbilger.com" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Chris Bilger's Portfolio" />
    <meta property="og:description" content="Christopher Bilger's Portfolio" />
    <meta property="og:image" content="https://chrisbilger.com/images/portfolio.avif" />

    <title>PostgreSQL and Us</title>
    <link rel="icon" type="image/x-icon" href="../../images/favicon.ico" />

    <link rel="stylesheet" href="./reveal.js-5.1.0/reset.css" />
    <link rel="stylesheet" href="./reveal.js-5.1.0/reveal.css" />
    <link rel="stylesheet" href="./reveal.js-5.1.0/theme/solarized.css" />

    <link rel="stylesheet" href="./highlight.js-11.9.0/default.min.css" />
    <script src="./highlight.js-11.9.0/highlight.min.js"></script>

    <script>
      hljs.highlightAll();
    </script>

    <style>
      .reveal {
        & .slides {
          & section {
            & h1,
            h2,
            h3,
            h4,
            h5,
            h6 {
              text-transform: none;
            }

            & ul {
              font-size: 75%;
            }

            & p {
              font-size: 75%;
            }

            & table {
              font-size: 65%;
            }
          }
        }
      }

      .blue {
        color: #268bd2;
      }

      a[target="_blank"]::after {
        content: " \2197";
      }
    </style>
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h2>PostgreSQL and Us</h2>
          <h4>How We Use PostgreSQL, What Works, and What's Next</h4>

          <br />
          <br />

          <p>Christopher R. Bilger</p>
          <p>March 11th, 2025</p>
        </section>

        <section>
          <h2>Agenda</h2>

          <br />
          <br />

          <div style="display: grid; grid-template-columns: 1fr 1fr">
            <div style="align-self: center">
              <ul>
                <li>How We Use PostgreSQL</li>
                <li>Pros and Cons of Our Current Approach</li>
                <li>Best Practices</li>
                <li>Recommended Next Steps</li>
                <li>Conclusion + Q&A</li>
              </ul>
            </div>

            <div>
              <img data-src="./images/Postgresql_elephant.png" width="200" />
            </div>
          </div>
        </section>

        <section>
          <section>
            <h2>How We Use PostgreSQL</h2>

            <br />
            <br />

            <h4>
              Note: This presentation revolves around our <span class="blue">main product database</span>; however 90%+
              is true for all of our PostgreSQL databases.
            </h4>
          </section>

          <section>
            <h2>Overview of Our Database Infrastructure</h2>

            <br />
            <br />

            <ul>
              <li>Managed PostgreSQL service via <span class="blue">AWS RDS</span> (Relational Database Service)</li>
              <li>
                Single instance primary with a failover read replica
                <ul>
                  <li>Subject to change once we have an RDS Proxy in place</li>
                </ul>
              </li>
              <li>
                Database migrations handled via the talkiatry-app Git repository
                <ul>
                  <li>Applied using the <span class="blue">knex</span> NPM package</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>Key Applications and Workloads</h2>

            <br />
            <br />

            <ul>
              <li>Source of truth for all pre-patient (a.k.a. intake) data</li>
              <li>Supports all <span class="blue">CRUD operations</span> from the intake assessment and Synapse</li>
              <li>Interfaces directly with all running <span class="blue">cronjobs</span> (Argo Workflows)</li>
              <li>Used for reporting and analytics via regular sync's to Snowflake</li>
              <li>
                Also regularly sync's new data from external sources
                <ul>
                  <li>Snowflake</li>
                  <li>eCW</li>
                  <li>Sohar</li>
                  <li>etc.</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>Scale and Performance Considerations</h2>

            <p>
              Using PostgreSQL's native functions, we can easily find our database's size when stored on disk. This
              includes indices and other relations which increase disk space beyond that of the data itself.
            </p>

            <br />

            <pre>
              <code class="language-sql">
SELECT pg_size_pretty(pg_database_size('&lt;dbname&gt;'));
              </code>
            </pre>
          </section>

          <section>
            <h2>Scale and Performance Considerations</h2>

            <p>
              As of today, our current size on disk is <span class="blue">~62 GB</span>. This includes all data,
              indices, and other relations.
            </p>

            <br />

            <table>
              <tr>
                <th>Size Category</th>
                <th>Range</th>
              </tr>
              <tr>
                <td>Very Small</td>
                <td>&lt;1 GB</td>
              </tr>
              <tr>
                <td>Small</td>
                <td>1 GB - 100 GB</td>
              </tr>
              <tr>
                <td>Medium</td>
                <td>100 GB - 1 TB</td>
              </tr>
              <tr>
                <td>Large</td>
                <td>1 TB - 10 TB</td>
              </tr>
              <tr>
                <td>Very Large</td>
                <td>&gt;10 TB</td>
              </tr>
            </table>
          </section>
        </section>

        <section>
          <section>
            <h2>Pros of Our Current Approach</h2>

            <br />
            <br />

            <ul>
              <li>Managed service with minimal maintenance</li>
              <li>Easy to <span class="blue">scale up and out</span></li>
              <li>
                Highly reliable and secure
                <ul>
                  <li>Regular patches and updates made available by AWS</li>
                  <li>Automated backups and point-in-time recovery</li>
                </ul>
              </li>
              <li>Compatible with a wide range of tools and libraries</li>
              <li>
                Excellent support for <span class="blue">complex queries</span> and data types
                <ul>
                  <li>JSONB, arrays, and custom types</li>
                  <li>We recently added PostGIS support for geospatial data</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <img data-src="./images/kiss.png" />
          </section>
        </section>

        <section>
          <section>
            <h2>Cons & Challenges</h2>

            <br />
            <br />

            <ul>
              <li>Performance bottlenecks</li>
              <li>Operational pain points</li>
              <li>Lessons learned from past experiences</li>
            </ul>
          </section>

          <section>
            <h2>Performance Bottlenecks</h2>

            <br />
            <br />

            <ul>
              <li>
                Slow queries
                <ul>
                  <li>Missing or poorly optimized indices</li>
                  <li><span class="blue">Suboptimal query patterns</span></li>
                </ul>
              </li>
              <li>
                Long-running transactions
                <ul>
                  <li><span class="blue">Lock contention and deadlocks</span></li>
                  <li>Resource constraints and timeouts</li>
                </ul>
              </li>
              <li>
                Materialized view and synchronization issues
                <ul>
                  <li>Performance overhead and maintenance costs</li>
                  <li><span class="blue">Consistency and staleness concerns</span></li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>Operational Pain Points</h2>

            <br />
            <br />

            <ul>
              <li>
                Database migrations and schema changes
                <ul>
                  <li>Rolling updates and backward compatibility</li>
                  <li><span class="blue">Automated testing and validation</span></li>
                </ul>
              </li>
              <li>
                Monitoring and alerting practices
                <ul>
                  <li>Performance metrics and resource utilization</li>
                  <li>Query profiling and optimization</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>Lessons Learned from Past Experiences</h2>

            <br />
            <br />

            <ul>
              <li>
                Reduce long-running transactions
                <ul>
                  <li>Generally occurs in cronjobs; minimize both temporal and computation per transaction loop</li>
                </ul>
              </li>
              <li>
                Optimize queries and indices
                <ul>
                  <li>Use <span class="blue">EXPLAIN ANALYZE</span> to identify bottlenecks</li>
                  <li>Regularly review and update our database schema</li>
                  <li>
                    Add indices on high-usage queries and/or queries that are part of a critical path
                    <ul>
                      <li>e.g. WHERE, JOIN, ORDER BY, GROUP BY, etc.</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>
                Synchronizing to external data sources (<span class="blue">e.g. OpenSearch</span>) causes performance
                issues
                <ul>
                  <li>Consider using a change data capture (CDC) tool</li>
                  <li>Or, use a more efficient synchronization mechanism if needed at all</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <img data-src="./images/this-is-fine-fire.jpg" />
          </section>
        </section>

        <section>
          <section>
            <h2>Best Practices We Follow</h2>

            <br />
            <br />

            <ul>
              <li>Database schema design and normalization</li>
              <li>Connection pooling and resource management</li>
              <li>Fairly standardized schema and query patterns</li>
            </ul>
          </section>

          <section>
            <h2>Example: Non-Optimized Query</h2>

            <br />

            <pre>
              <code class="language-sql">
SELECT
  *
FROM
  users
WHERE
  created_at &gt;= '2025-01-01'
  AND created_at &lt; '2025-02-01'
  AND status = 'active';
              </code>
            </pre>
          </section>

          <section>
            <h2>Example: Well-Optimized Query</h2>

            <pre>
              <code class="language-sql">
CREATE INDEX idx_users_created_at_status
ON users (created_at, status);

SELECT
  *
FROM
  users
WHERE
  created_at &gt;= '2025-01-01'
  AND created_at &lt; '2025-02-01'
  AND status = 'active';
              </code>
            </pre>
          </section>

          <section>
            <img data-src="./images/with_connection_pool.png" />
          </section>
        </section>

        <section>
          <section>
            <h2>Best Practices We Should Adopt</h2>

            <br />
            <br />

            <ul>
              <li>Use <span class="blue">EXPLAIN ANALYZE</span> to identify bottlenecks</li>
              <li>
                Use tools such as <span class="blue">pganalyze</span>
                <ul>
                  <li>Identify slow queries and missing indices</li>
                  <li>Optimize query patterns and database schema</li>
                </ul>
              </li>
              <li>
                Perform as much as possible, if not all, query filtering, joins, and ordering in the database
                <ul>
                  <li>Minimize data transfer between the database and application</li>
                  <li>Minimize computational load on the application servers</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>What is EXPLAIN ANALYZE?</h2>

            <br />
            <br />

            <p>
              <span class="blue">EXPLAIN ANALYZE</span> are a set of two PostgreSQL options that can be used to obtain a
              query execution plan and the actual execution time of each node in the plan.
            </p>

            <p>
              <span class="blue">EXPLAIN</span> will show the query plan, while <span class="blue">ANALYZE</span> will
              actually execute the query and show the actual execution time.
            </p>
          </section>

          <section>
            <h2>Example: EXPLAIN ANALYZE</h2>

            <br />

            <pre>
              <code class="language-sql">
CREATE TABLE employees (
  id SERIAL PRIMARY KEY,
  name VARCHAR(100),
  department VARCHAR(50),
  salary INT
);

SELECT * FROM employees WHERE department = 'Engineering';
              </code>
            </pre>
          </section>

          <section>
            <h2>Example: EXPLAIN ANALYZE</h2>

            <br />

            <pre>
              <code class="language-sql">
EXPLAIN ANALYZE SELECT * FROM employees WHERE department = 'Engineering';

Seq Scan on employees  (cost=0.00..15.35 rows=5 width=100) (actual time=0.015..0.018 rows=3 loops=1)
  Filter: (department = 'Engineering'::text)
  Rows Removed by Filter: 97
Planning Time: 0.125 ms
Execution Time: 0.057 ms
              </code>
            </pre>
          </section>

          <section>
            <h2>Example: EXPLAIN ANALYZE</h2>

            <br />

            <p>
              Using the information returned from <span class="blue">EXPLAIN ANALYZE</span>, we can see that the query
              is performing a <span class="blue">sequential scan</span> on the employees table. This is not ideal for
              performance as it is scanning the entire table.
            </p>

            <br />

            <pre>
              <code class="language-sql">
CREATE INDEX idx_department ON employees(department);
              </code>
            </pre>
          </section>

          <section>
            <img data-src="./images/pganalyze_query_performance_date_picker.png" />
          </section>
        </section>

        <section>
          <section>
            <h2>Recommended Next Steps</h2>

            <br />
            <br />

            <ul>
              <li>Performance metric monitoring and tooling</li>
              <li>Database indices / optimizations for easy wins</li>
              <li>Training, monitoring, or tooling recommendations for enhancing our practice</li>
              <li>Making use of an AWS RDS Proxy</li>
            </ul>
          </section>

          <section>
            <h2>PostgreSQL Extensions to Consider</h2>

            <br />
            <br />

            <ul>
              <li>
                <span class="blue">pg_stat_statements</span> for query statistics
                <ul>
                  <li>Already in use</li>
                </ul>
              </li>
              <li>
                <span class="blue">pg_cron</span> for cronjobs
                <ul>
                  <li>Currently using Argo Workflows</li>
                  <li>
                    May be useful for simpler tasks; although the added complexity would more or less render the use of
                    this extension moot
                  </li>
                </ul>
              </li>
              <li>
                <span class="blue">pg_repack</span> for table maintenance
                <ul>
                  <li>Reduces bloat and improves performance</li>
                  <li>May be useful for large tables</li>
                </ul>
              </li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Conclusion + Q&A</h2>

            <br />
            <br />

            <div style="display: grid; grid-template-columns: 1fr 1fr">
              <div style="align-self: center">
                <ul>
                  <li>How We Use PostgreSQL</li>
                  <li>Pros and Cons of Our Current Approach</li>
                  <li>Best Practices</li>
                  <li>Recommended Next Steps</li>
                  <li>Q&A</li>
                </ul>
              </div>

              <div>
                <img data-src="./images/keep-calm-and-use-postgres.webp" width="400" />
              </div>
            </div>
          </section>

          <section>
            <h2>Powered By</h2>

            <br />
            <br />

            <ol>
              <li>A single, static webpage.</li>
              <li><a href="https://revealjs.com/" target="_blank">reveal.js</a></li>
              <li><a href="https://highlightjs.org/" target="_blank">highlight.js</a></li>
            </ol>
          </section>
        </section>
      </div>
    </div>

    <script>
      hljs.highlightAll();
    </script>

    <script type="module">
      import Reveal from "./reveal.js-5.1.0/reveal.esm.js";

      let deck = new Reveal({
        slideNumber: "c/t",
        help: true,
      });
      deck.initialize();
    </script>
  </body>
</html>
